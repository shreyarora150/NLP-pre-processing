{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# Text Acquisition and Pre-processing\n",
    "\n",
    "In this assignment you will practice obtaining, extracting, cleaning and pre-processing text from an online source. The objective is to obtain the text from a web page and generate a **pandas** DataFrame containing the text segmented, tokenized and with different types of linguistic annotations.\n",
    "\n",
    "You will work with the following objects and functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Text Extraction\n",
    "\n",
    "The text you are going to work with corresponds to the following post from the Food and Agriculture Organization of the United Nations website: [World food prices dip in December](https://www.fao.org/newsroom/detail/world-food-prices-dip-in-december/en).\n",
    "\n",
    "In a more realistic scenario, you should download the html document yourself. This could be done with the following code snippet:\n",
    "\n",
    ">```python\n",
    "import requests\n",
    "URL = \"https://www.fao.org/newsroom/detail/world-food-prices-dip-in-december/en\"\n",
    "page = requests.get(URL)\n",
    "html_content = page.content\n",
    "\n",
    "However, for this assignment, you are provided with the downloaded document. The file`world-food-prices.html` can be found in the same directory as this notebook and it can be opened as a regular text file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' <!DOCTYPE html> <html lang=\"en\"> <head> <meta charset=\"utf-8\" /> <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=no\"> <title>\\n\\tWorld food prices dip in December\\n</title> <script src=\"/ScriptResource.axd?d=okuX3IVIBwfJlfEQK32K3hu4wA2qYZOscmtsXGLNMaT1SeSa2ByRKpPz9pkmicdQmLZjrfXbzQg-t-PYtREZ1mv-AHy-XqG8V1C8KEuJc1LwVjfZ2AWtsXusqOzwjxwAkWajaiTob5rdLJ_1Q_rhyISygdJ2WS4kb3-Mf0bSt_7dAdqZ2JnDovQKGlnv0vvH0&amp;t=ffffffffb0940fc0\" type=\"text/javascript\"></script><script src=\"/ScriptResource.axd?d=ePnjFy9PuY6CB3GWMX-b_9Fw4jG3rW51lh6cTRiQ1f_9YOhRVOpDf4gVRQwVzn4JRlDVp-Aj_GWhYCgMY8uVHBZj_w4a27EVOxonvJSMs3yERFILsgdOHu7up3GVU-jExdmK0YWhyY1E0W4ye5rzFrSYUigZQBN7nFt18-5XwfQs2ZTBZ5-Na5q3Phaw58Dx0&amp;t=ffffffffb0940fc0\" type=\"text/javascript\"></script><script src=\"https://cse.google.com/cse.js?cx=018170620143701104933%3Aqq82jsfba7w\" type=\"text/javascript\"></script><link href=\"/ResourcePackages/FAO/assets/dist/css/bootstrap.min.css?v=5.2.0&amp;package=FAO\" rel=\"stylesheet\" type=\"text/css\" /> <link href=\"/ResourcePackages/FAO/assets/dist/css/fao-theme.min.css?v=2.6.6&amp;package=FAO\" rel=\"stylesheet\" type=\"text/css\" /> <!-- Google Tag Manager -->\\n<script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({\\'gtm.start\\':\\nnew Date().getTime(),event:\\'gtm.js\\'});var f=d.getElementsByTagName(s)[0],\\nj=d.createElement(s),dl=l!=\\'dataLayer\\'?\\'&l=\\'+l:\\'\\';j.async=true;j.src=\\n\\'https://www.googletagmanager.com/gtm.js?id=\\'+i+dl;f.parentNode.insertBefore(j,f);\\n})(window,document,\\'script\\',\\'d'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"world-food-prices.html\", encoding=\"utf8\") as html_file:\n",
    "    html_content = html_file.read()\n",
    "html_content[:1500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "As you can see the document contains a lot of html tags as well as some **javascript** code. The text also includes fields that are not of interest, such as the navigation menu of the web page. The goal of the first step in this assignment is to extract only the text from the body of the post.\n",
    "\n",
    "To do this, you must complete the code for the `extract_text` function. This function should parse the content of the html document using the **BeatifulSoup** library, find the html element containing the text of the body of the post, and extract such text. The body of the post is contained by the element with the following **id**: `\"Contentplaceholder1_C011_Col00\"`. Review the [BeautifullSoup documentation](https://beautiful-soup-4.readthedocs.io/en/latest/index.html) to learn how to perform these steps.\n",
    "\n",
    "\n",
    "The function must return the text extracted of which the first 580 characters should look like this:\n",
    "\n",
    "\n",
    "><pre>'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWorld food prices dip in December\\nFAO Food Price Index ends 2022 lower than a year earlier\\n\\n\\n\\n\\n                                A farmer in Sicily carrying wheat seeds.\\n                             \\n\\n©FAO/Giorgio Cosulich \\n\\n\\n\\n\\n06/01/2023\\n\\n\\nRome – The index of world food prices dipped for the ninth consecutive month in December 2022, declining by 1.9 percent from the previous month, the Food and Agriculture Organization of the United Nations (FAO) reported today. The FAO Food Price Index averaged 132.4 points in December, 1.0 percent below its value a year earlier. '</pre>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text(html_content):\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "    x  = soup.find(id=\"Contentplaceholder1_C011_Col00\").getText()\n",
    "    return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nWorld food prices dip in December\\nFAO Food Price Index ends 2022 lower than a year earlier\\n\\n\\n\\n\\n                                A farmer in Sicily carrying wheat seeds.\\n                             \\n\\n©FAO/Giorgio Cosulich \\n\\n\\n\\n\\n06/01/2023\\n\\n\\nRome – The index of world food prices dipped for the ninth consecutive month in December 2022, declining by 1.9 percent from the previous month, the Food and Agriculture Organization of the United Nations (FAO) reported today. The FAO Food Price Index averaged 132.4 points in December, 1.0 percent below its value a year earlier. '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = extract_text(html_content)\n",
    "text[:580]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Text Cleanup\n",
    "\n",
    "The text extracted by `extract_text` is not still ready to use. It contains several newline characters and additional spaces that make the text noisy. In the next step of the assignment, you must complete the code for the function `clean_text`. The function should take the text and delete all those newline characters and extra blank spaces. The function should also add a period to the end of those sentences that do not originally contain it, for example, `World food prices dip in December` or `06/01/2023`.\n",
    "\n",
    "You can solve this exercise using the **Python** built-in [string methods](https://docs.python.org/3.9/library/stdtypes.html?highlight=replace#str), such as `replace`, or by [regular expressions](https://docs.python.org/3.9/library/re.html?highlight=re#module-re).\n",
    "\n",
    "The `extract_text` function must return the cleaned text of which the first 500 characters should look like this:\n",
    "\n",
    ">'World food prices dip in December. FAO Food Price Index ends 2022 lower than a year earlier. A farmer in Sicily carrying wheat seeds. ©FAO/Giorgio Cosulich. 06/01/2023. Rome – The index of world food prices dipped for the ninth consecutive month in December 2022, declining by 1.9 percent from the previous month, the Food and Agriculture Organization of the United Nations (FAO) reported today. The FAO Food Price Index averaged 132.4 points in December, 1.0 percent below its value a year earlier. '"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.strip()\n",
    "    text = text.replace('\\n', '')\n",
    "    text = text.replace('\\r', '')\n",
    "\n",
    "    t1 = \"\"\n",
    "    for t in text.split(\" \"):\n",
    "        m = re.search('[a-z][A-Z]',t) \n",
    "        n = re.search(r\"^[A-Z]$\",t)\n",
    "        if m:\n",
    "            t = t[0:m.start()+1] + \". \" + t[m.end()-1:len(t)]\n",
    "        if n:\n",
    "            t = \". \"+t\n",
    "        t1 = t1 + t + \" \"\n",
    "    return re.sub('\\s{2,}',\"\",t1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"World food prices dip in December. FAO Food Price Index ends 2022 lower than a year earlier. A farmer in Sicily carrying wheat seeds.©FAO/Giorgio Cosulich 06/01/2023Rome – The index of world food prices dipped for the ninth consecutive month in December 2022, declining by 1.9 percent from the previous month, the Food and Agriculture Organization of the United Nations (FAO) reported today. The FAO Food Price Index averaged 132.4 points in December, 1.0 percent below its value a year earlier. However, for 2022 as a whole, the index, which tracks monthly changes in the international prices of commonly-traded food commodities, averaged 143.7 points, 14.3 percent higher than the average value over 2021. “Calmer food commodity prices are welcome after two very volatile years,” said FAO Chief Economist Maximo Torero. “It is important to remain vigilant and keep a strong focus on mitigating global food insecurity given that world food prices remain at elevated levels, with many staples near record highs, and with prices of rice increasing, and still many risks associated with future supplies” Vegetable oil world quotations led the decrease, with the FAO Vegetable Oil Price Index down 6.7 percent from November to reach its lowest level since February 2021. International quotations for palm, soy, rapeseed and sunflowerseed oils all declined in December, driven by subdued global import demand and prospects of seasonally rising soy oil production in South America as well as declining crude oil prices.The FAO Cereal Price Index decreased 1.9 percent from November. Ongoing harvests in the southern hemisphere boosted wheat exportable supplies, while strong competition from Brazil drove down world maize prices. Conversely, international rice prices rose, buoyed by Asian buying and currency appreciation against the United States dollar for exporting countries. The FAO Meat Price Index in December dropped by 1.2 percent from November, with lower world prices of bovine and poultry meats outweighing higher pig and ovine meat prices. International bovine meat prices were impacted by lacklustre global demand for medium-term supplies, while more-than-adequate export supplies pushed down poultry meat prices. Pig meat prices rose on the back of strong internal holiday demand, especially in Europe, The FAO Dairy Price Index increased by 1.2 percent in December, following five months of consecutive declines. Higher international cheese prices, reflecting tightening market conditions, drove the monthly increase in the index, while international quotations for butter and milk powder declined. The FAO Sugar Price Index also rose, increasing by 2.4 percent from November, mostly due to concerns over the impact of adverse weather conditions on crop yields in India and sugarcane crushing delays in Thailand and Australia. Looking back on 2022As noted, the FAO Food Price Index average over 2022 was notably higher than the previous year, which on top of large increases in 2021 catalyzed significant strains and food security concerns for lower-income food-importing countries and the adoption, inspired by FAO, of a “Food Shock Window” lending facility by the International Monetary Fund. World prices of wheat and maize reached record highs over the year. The average value of the FAO Vegetable Oil Price Index for all of 2022 reached a new record high, while the FAO Dairy Price Index and Meat Price Index marked their highest full-year levels since 1990.More details are available here.More on this topic. FAO Food Price Index. FAO's most recent Cereal Supply and Demand Brief. AMIS: Market Monitor. Agricultural Market Information System (AMIS)FAO Markets and Trade. ContactChristopher Emsden. FAO News and Media (Rome)(+39) 06 570 53291[email\\xa0protected]FAO News and Media(+39) 06 570 53625[email\\xa0protected] \""
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_text = clean_text(text)\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Pre-processing\n",
    "\n",
    "Once the text has been extracted and cleaned up, the next step you must take is to pre-process it. For this, in this assignment, you are going to use the [spaCy](https://spacy.io/) library. This library is an advanced NLP toolkit that allows to execute various pre-processing steps as well as different NLP tasks. **spaCy** provides trained [pipelines](https://spacy.io/usage/processing-pipelines) for a variety of languages that can be installed as individual **Python** modules and include [linguistic featues](https://spacy.io/usage/linguistic-features) such as:\n",
    "\n",
    "- Sentence Segmentation\n",
    "- Tokenization\n",
    "- Stemming and Lemmatization\n",
    "- Stopwords\n",
    "- Part-of-speech tagging\n",
    "- Syntactic dependency parsing\n",
    "- Named Entity Recognition\n",
    "- Word Embeddings\n",
    "\n",
    "In this exercise, you will work with the [English pipeline optimized for CPU](https://spacy.io/models/en#en_core_web_sm) that can be loaded as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "You must complete the code for the `preprocess_text` function. This function takes the text and a **spaCy** pipeline as input and should run that pipeline on the text. The function must return a [Doc](https://spacy.io/api/doc) object. Check the [spaCy 101](https://spacy.io/usage/spacy-101) documentation to learn how to apply the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text(text, nlp):\n",
    "    return nlp(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = process_text(cleaned_text, nlp)\n",
    "all(map(doc.has_annotation, [\"LEMMA\", \"POS\", \"ENT_TYPE\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Creating a DataFrame\n",
    "\n",
    "In the next exercise, you will create a [pandas DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html) that will contain some of the linguistic annotations from the `Doc` object obtained in the previous step. Loading the data into a `DataFrame` provides some advantages such as a better integration with other **Python** machine learning libraries or the option to save the data in a csv file.\n",
    "\n",
    "The goal is to create a `DataFrame` that contains a row per each token in the `Doc` and the following columns:\n",
    "- *sent_id*: The id of the sentence the token belongs to. It represents the position of the sentence in the `Doc`, starting by 0.\n",
    "- *token_id*: The id of the token. It represents the position of the token in the sentence, starting by 0.\n",
    "- *text*: The original text of the token.\n",
    "- *lemma*: The lemmatization of the token.\n",
    "- *pos*: The part-of-speech of the token.\n",
    "- *ent*: The entity type of the token returned by the Named Entity Recognition component.\n",
    "\n",
    "You must complete the code for the `to_dataframe` function. This function takes the [Doc](https://spacy.io/api/doc) object and must return the `DataFrame` described above. The function should iterate over the sentences in the `Doc` (each sentence is a [Span](https://spacy.io/api/span) object) and, for each sentence, it should iterate over its tokens (each token is a [Token](https://spacy.io/api/token) object). For each token, `to_dataframe` should obtain the values to fill the *text*, *lemma*, *pos* and *ent* columns of the `DataFrame`. For example, the content of the `DataFrame` for the setence with *sent_id* equal to 1, corresponding to the second sentence in the `Doc`, should look like this:\n",
    "\n",
    "|    |   sent_id |   token_id | text    | lemma   | pos   | ent   |\n",
    "|---:|----------:|-----------:|:--------|:--------|:------|:------|\n",
    "|  7 |         1 |          0 | FAO     | FAO     | PROPN | ORG   |\n",
    "|  8 |         1 |          1 | Food    | Food    | PROPN | ORG   |\n",
    "|  9 |         1 |          2 | Price   | Price   | PROPN | ORG   |\n",
    "| 10 |         1 |          3 | Index   | Index   | PROPN | ORG   |\n",
    "| 11 |         1 |          4 | ends    | end     | VERB  |       |\n",
    "| 12 |         1 |          5 | 2022    | 2022    | NUM   | DATE  |\n",
    "| 13 |         1 |          6 | lower   | low     | ADJ   |       |\n",
    "| 14 |         1 |          7 | than    | than    | ADP   |       |\n",
    "| 15 |         1 |          8 | a       | a       | DET   | DATE  |\n",
    "| 16 |         1 |          9 | year    | year    | NOUN  | DATE  |\n",
    "| 17 |         1 |         10 | earlier | early   | ADV   | DATE  |\n",
    "| 18 |         1 |         11 | .       | .       | PUNCT |       |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataframe(doc):\n",
    "    row_data = []\n",
    "    for sent_id, sent in enumerate(doc.sents):\n",
    "        for token_id, token in enumerate(sent):\n",
    "            row = {\n",
    "                \"sent_id\": sent_id,          # sentence ID\n",
    "                \"token_id\": token_id,        # token ID within the sentence\n",
    "                \"text\": token.text,         # raw text of the token\n",
    "                \"lemma\": token.lemma_,      # lemmatized form of the token\n",
    "                \"pos\": token.pos_,          # part-of-speech tag of the token\n",
    "                \"ent\": token.ent_type_ if token.ent_type_ else \"\"  # named entity tag of the token\n",
    "            }\n",
    "            # append the dictionary to the list of token data\n",
    "            row_data.append(row)\n",
    "    # convert the list of token data to a pandas DataFrame and return it\n",
    "    df = pd.DataFrame(row_data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>ent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>FAO</td>\n",
       "      <td>FAO</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Food</td>\n",
       "      <td>Food</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Price</td>\n",
       "      <td>Price</td>\n",
       "      <td>PROPN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Index</td>\n",
       "      <td>Index</td>\n",
       "      <td>PROPN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>ends</td>\n",
       "      <td>end</td>\n",
       "      <td>VERB</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>NUM</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>lower</td>\n",
       "      <td>low</td>\n",
       "      <td>ADJ</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>than</td>\n",
       "      <td>than</td>\n",
       "      <td>ADP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>year</td>\n",
       "      <td>year</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>earlier</td>\n",
       "      <td>early</td>\n",
       "      <td>ADV</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sent_id  token_id     text  lemma    pos   ent\n",
       "7         1         0      FAO    FAO  PROPN   ORG\n",
       "8         1         1     Food   Food  PROPN   ORG\n",
       "9         1         2    Price  Price  PROPN      \n",
       "10        1         3    Index  Index  PROPN      \n",
       "11        1         4     ends    end   VERB      \n",
       "12        1         5     2022   2022    NUM  DATE\n",
       "13        1         6    lower    low    ADJ      \n",
       "14        1         7     than   than    ADP      \n",
       "15        1         8        a      a    DET  DATE\n",
       "16        1         9     year   year   NOUN  DATE\n",
       "17        1        10  earlier  early    ADV  DATE\n",
       "18        1        11        .      .  PUNCT      "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = to_dataframe(doc)\n",
    "df[df.sent_id == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Cutomizing the Tokenizer\n",
    "\n",
    "The default components of a **spaCy** pipeline will not always behave according to the needs of your projects. For example, the default tokenizer of the `en_core_web_sm` pipeline does not always splits dates in `month/day/year` format into `month`, `day` and `year`. This is the case for the sentence with *sent_id* equal to 4 that only includes a date in that format:\n",
    "\n",
    "|    |   sent_id |   token_id | text       | lemma      | pos   | ent   |\n",
    "|---:|----------:|-----------:|:-----------|:-----------|:------|:------|\n",
    "| 32 |         4 |          0 | 06/01/2023 | 06/01/2023 | NUM   |       |\n",
    "| 33 |         4 |          1 | .          | .          | PUNCT |       |\n",
    "\n",
    "The goal of the last exercise of this task is to update the `en_core_web_sm` pipeline with a custom tokenizer that forces the splitting of dates in `month/day/year` format so that the sentence above looks like this:\n",
    "\n",
    "|    |   sent_id |   token_id | text   | lemma   | pos   | ent      |\n",
    "|---:|----------:|-----------:|:-------|:--------|:------|:---------|\n",
    "| 32 |         4 |          0 | 06     | 06      | NUM   | CARDINAL |\n",
    "| 33 |         4 |          1 | /      | /       | SYM   |          |\n",
    "| 34 |         4 |          2 | 01     | 01      | NUM   |          |\n",
    "| 35 |         4 |          3 | /      | /       | SYM   |          |\n",
    "| 36 |         4 |          4 | 2023   | 2023    | NUM   |          |\n",
    "| 37 |         4 |          5 | .      | .       | PUNCT |          |\n",
    "\n",
    "You must complete the code for the `customize_tokenizer` function. The function takes the **spaCy** pipeline as input. It should create the customized tokenizer and return the updated version of the pipeline including the customized tokenizer. The `Tokenizer` must be created with the default vocabulary and the default prefixes and suffixes rules of the pipeline. You should only update the infixes rules adding a regular expression that captures slash (`/`) characters. The `Tokenizer` should **not** include special cases or rules for token and url matching. Check the [spacy's documentation](https://spacy.io/usage/linguistic-features#native-tokenizers) to learn how to customize the tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def customize_tokenizer(nlp):\n",
    "    infixes = nlp.Defaults.infixes + [r\"/\"]\n",
    "\n",
    "    tokenizer = spacy.tokenizer.Tokenizer(nlp.vocab, nlp.Defaults.tokenizer_exceptions,\n",
    "                                          prefix_search=nlp.tokenizer.prefix_search,\n",
    "                                          suffix_search=nlp.tokenizer.suffix_search,\n",
    "                                          infix_finditer=re.compile(r'(' + '|'.join(infixes) + ')').finditer)\n",
    "\n",
    "\n",
    "    nlp.tokenizer = tokenizer\n",
    "    return nlp\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sent_id</th>\n",
       "      <th>token_id</th>\n",
       "      <th>text</th>\n",
       "      <th>lemma</th>\n",
       "      <th>pos</th>\n",
       "      <th>ent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>A</td>\n",
       "      <td>a</td>\n",
       "      <td>DET</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>farmer</td>\n",
       "      <td>farmer</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>Sicily</td>\n",
       "      <td>sicily</td>\n",
       "      <td>ADV</td>\n",
       "      <td>GPE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>carrying</td>\n",
       "      <td>carry</td>\n",
       "      <td>VERB</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>wheat</td>\n",
       "      <td>wheat</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>seeds.</td>\n",
       "      <td>seeds.</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>©</td>\n",
       "      <td>©</td>\n",
       "      <td>PROPN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>FAO</td>\n",
       "      <td>FAO</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "      <td>SYM</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>Giorgio</td>\n",
       "      <td>Giorgio</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>Cosulich</td>\n",
       "      <td>Cosulich</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>06</td>\n",
       "      <td>06</td>\n",
       "      <td>NUM</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "      <td>SYM</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>01</td>\n",
       "      <td>01</td>\n",
       "      <td>NUM</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>/</td>\n",
       "      <td>/</td>\n",
       "      <td>SYM</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2</td>\n",
       "      <td>16</td>\n",
       "      <td>2023Rome</td>\n",
       "      <td>2023Rome</td>\n",
       "      <td>PROPN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2</td>\n",
       "      <td>17</td>\n",
       "      <td>–</td>\n",
       "      <td>–</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "      <td>The</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "      <td>index</td>\n",
       "      <td>index</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2</td>\n",
       "      <td>21</td>\n",
       "      <td>world</td>\n",
       "      <td>world</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2</td>\n",
       "      <td>22</td>\n",
       "      <td>food</td>\n",
       "      <td>food</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2</td>\n",
       "      <td>23</td>\n",
       "      <td>prices</td>\n",
       "      <td>price</td>\n",
       "      <td>NOUN</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2</td>\n",
       "      <td>24</td>\n",
       "      <td>dipped</td>\n",
       "      <td>dip</td>\n",
       "      <td>VERB</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2</td>\n",
       "      <td>25</td>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "      <td>ADP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>ninth</td>\n",
       "      <td>ninth</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>consecutive</td>\n",
       "      <td>consecutive</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>month</td>\n",
       "      <td>month</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2</td>\n",
       "      <td>30</td>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "      <td>ADP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2</td>\n",
       "      <td>31</td>\n",
       "      <td>December</td>\n",
       "      <td>December</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2</td>\n",
       "      <td>32</td>\n",
       "      <td>2022</td>\n",
       "      <td>2022</td>\n",
       "      <td>NUM</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2</td>\n",
       "      <td>33</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>declining</td>\n",
       "      <td>decline</td>\n",
       "      <td>VERB</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>by</td>\n",
       "      <td>by</td>\n",
       "      <td>ADP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2</td>\n",
       "      <td>36</td>\n",
       "      <td>1.9</td>\n",
       "      <td>1.9</td>\n",
       "      <td>NUM</td>\n",
       "      <td>PERCENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "      <td>percent</td>\n",
       "      <td>percent</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>PERCENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "      <td>from</td>\n",
       "      <td>from</td>\n",
       "      <td>ADP</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>2</td>\n",
       "      <td>39</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>2</td>\n",
       "      <td>40</td>\n",
       "      <td>previous</td>\n",
       "      <td>previous</td>\n",
       "      <td>ADJ</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>month</td>\n",
       "      <td>month</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>2</td>\n",
       "      <td>43</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>Food</td>\n",
       "      <td>Food</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>2</td>\n",
       "      <td>45</td>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "      <td>CCONJ</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>2</td>\n",
       "      <td>46</td>\n",
       "      <td>Agriculture</td>\n",
       "      <td>Agriculture</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>Organization</td>\n",
       "      <td>Organization</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>2</td>\n",
       "      <td>48</td>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "      <td>ADP</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>2</td>\n",
       "      <td>49</td>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "      <td>DET</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>United</td>\n",
       "      <td>United</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2</td>\n",
       "      <td>51</td>\n",
       "      <td>Nations</td>\n",
       "      <td>Nations</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>2</td>\n",
       "      <td>52</td>\n",
       "      <td>(</td>\n",
       "      <td>(</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>2</td>\n",
       "      <td>53</td>\n",
       "      <td>FAO</td>\n",
       "      <td>FAO</td>\n",
       "      <td>PROPN</td>\n",
       "      <td>ORG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>)</td>\n",
       "      <td>)</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>2</td>\n",
       "      <td>55</td>\n",
       "      <td>reported</td>\n",
       "      <td>report</td>\n",
       "      <td>VERB</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>2</td>\n",
       "      <td>56</td>\n",
       "      <td>today</td>\n",
       "      <td>today</td>\n",
       "      <td>NOUN</td>\n",
       "      <td>DATE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>PUNCT</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    sent_id  token_id          text         lemma    pos      ent\n",
       "19        2         0             A             a    DET         \n",
       "20        2         1        farmer        farmer   NOUN         \n",
       "21        2         2            in            in    ADP         \n",
       "22        2         3        Sicily        sicily    ADV      GPE\n",
       "23        2         4      carrying         carry   VERB         \n",
       "24        2         5         wheat         wheat   NOUN         \n",
       "25        2         6        seeds.        seeds.   NOUN         \n",
       "26        2         7             ©             ©  PROPN         \n",
       "27        2         8           FAO           FAO  PROPN      ORG\n",
       "28        2         9             /             /    SYM      ORG\n",
       "29        2        10       Giorgio       Giorgio  PROPN      ORG\n",
       "30        2        11      Cosulich      Cosulich  PROPN      ORG\n",
       "31        2        12            06            06    NUM     DATE\n",
       "32        2        13             /             /    SYM     DATE\n",
       "33        2        14            01            01    NUM     DATE\n",
       "34        2        15             /             /    SYM         \n",
       "35        2        16      2023Rome      2023Rome  PROPN         \n",
       "36        2        17             –             –  PUNCT         \n",
       "37        2        18           The           the    DET         \n",
       "38        2        19         index         index   NOUN         \n",
       "39        2        20            of            of    ADP         \n",
       "40        2        21         world         world   NOUN         \n",
       "41        2        22          food          food   NOUN         \n",
       "42        2        23        prices         price   NOUN         \n",
       "43        2        24        dipped           dip   VERB         \n",
       "44        2        25           for           for    ADP         \n",
       "45        2        26           the           the    DET     DATE\n",
       "46        2        27         ninth         ninth    ADJ     DATE\n",
       "47        2        28   consecutive   consecutive    ADJ     DATE\n",
       "48        2        29         month         month   NOUN     DATE\n",
       "49        2        30            in            in    ADP         \n",
       "50        2        31      December      December  PROPN     DATE\n",
       "51        2        32          2022          2022    NUM     DATE\n",
       "52        2        33             ,             ,  PUNCT         \n",
       "53        2        34     declining       decline   VERB         \n",
       "54        2        35            by            by    ADP         \n",
       "55        2        36           1.9           1.9    NUM  PERCENT\n",
       "56        2        37       percent       percent   NOUN  PERCENT\n",
       "57        2        38          from          from    ADP         \n",
       "58        2        39           the           the    DET     DATE\n",
       "59        2        40      previous      previous    ADJ     DATE\n",
       "60        2        41         month         month   NOUN     DATE\n",
       "61        2        42             ,             ,  PUNCT         \n",
       "62        2        43           the           the    DET      ORG\n",
       "63        2        44          Food          Food  PROPN      ORG\n",
       "64        2        45           and           and  CCONJ      ORG\n",
       "65        2        46   Agriculture   Agriculture  PROPN      ORG\n",
       "66        2        47  Organization  Organization  PROPN      ORG\n",
       "67        2        48            of            of    ADP      ORG\n",
       "68        2        49           the           the    DET      ORG\n",
       "69        2        50        United        United  PROPN      ORG\n",
       "70        2        51       Nations       Nations  PROPN      ORG\n",
       "71        2        52             (             (  PUNCT         \n",
       "72        2        53           FAO           FAO  PROPN      ORG\n",
       "73        2        54             )             )  PUNCT         \n",
       "74        2        55      reported        report   VERB         \n",
       "75        2        56         today         today   NOUN     DATE\n",
       "76        2        57             .             .  PUNCT         "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customized_nlp = customize_tokenizer(nlp)\n",
    "doc = process_text(cleaned_text, customized_nlp)\n",
    "df = to_dataframe(doc)\n",
    "df[df.sent_id == 2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
